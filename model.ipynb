{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 19:36:54.197163: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "from tensorflow import keras\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' #use GPU with ID=0\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5 # maximun alloc gpu50% of MEM\n",
    "# config.gpu_options.allow_growth = True #allocate dynamically\n",
    "# sess = tf.Session(config = config)\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BACKBONE = 'resnet34'\n",
    "preprocess_input = get_preprocessing_fn(BACKBONE)\n",
    "\n",
    "# load images and convert them to numpy arrays\n",
    "real_images_dir = 'data/imagery/'\n",
    "mask_images_dir = 'data/masks/'\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "for item in os.listdir(real_images_dir):\n",
    "    if item.endswith('.png') and not item.startswith('test'):\n",
    "        real_img = Image.open(real_images_dir + item)\n",
    "        mask_img = Image.open(mask_images_dir + item)\n",
    "        # Divide the image into 256x256 patches\n",
    "        real_img_array = np.array(real_img)\n",
    "        mask_img_array = np.array(mask_img)\n",
    "        tiles_real = [real_img_array[x:x+72,y:y+72] for x in range(0,real_img_array.shape[0],72) for y in range(0,real_img_array.shape[1],72)]\n",
    "        tiles_mask = [mask_img_array[x:x+72,y:y+72] for x in range(0,mask_img_array.shape[0],72) for y in range(0,mask_img_array.shape[1],72)]\n",
    "        x_train.extend(tiles_real)\n",
    "        y_train.extend(tiles_mask)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "y_train = y_train[:,:,:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = smp.Unet(BACKBONE, encoder_weights='imagenet')\n",
    "        self.loss = smp.losses.DiceLoss()\n",
    "        self.metrics = [smp.metrics.IoU(threshold=0.5)]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46464, 72, 72, 3)\n",
      "(46464, 72, 72, 3)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m\n\u001b[1;32m     14\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(x_train, y_train)), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# define model\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# model = smp.Unet(\"resnet34\", encoder_weights=\"imagenet\", classes=3, activation=None)\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     21\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(model, train_dataset)\n",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28msuper\u001b[39m(Model, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m smp\u001b[38;5;241m.\u001b[39mUnet(BACKBONE, encoder_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m \u001b[43msmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDiceLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;241m=\u001b[39m [smp\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mIoU(threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)]\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'mode'"
     ]
    }
   ],
   "source": [
    "from segmentation_models_pytorch.losses import soft_bce\n",
    "from segmentation_models_pytorch.metrics import iou_score\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "x_train = x_train[:1000].astype('float32')\n",
    "y_train = y_train[:1000].astype('float32')     \n",
    "\n",
    "# preprocess input\n",
    "x_train = preprocess_input(x_train)\n",
    "# x_val = preprocess_input(x_val)\n",
    "\n",
    "train_dataset = DataLoader(list(zip(x_train, y_train)), batch_size=10, shuffle=True)\n",
    "\n",
    "# define model\n",
    "\n",
    "# model = smp.Unet(\"resnet34\", encoder_weights=\"imagenet\", classes=3, activation=None)\n",
    "model = Model()\n",
    "trainer = pl.Trainer(max_epochs=100)\n",
    "trainer.fit(model, train_dataset)\n",
    "\n",
    "# image, mask = dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
